{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import  datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "iris=datasets.load_iris()\n",
    "\n",
    "x=iris.data\n",
    "y=iris.target\n",
    "\n",
    "x_train,x_test,y_train,y_test= train_test_split(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9473684210526315\n",
      "(4, 100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MLPClassifier' object has no attribute 'intercept'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-adae99018888>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoefs_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintercept\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'MLPClassifier' object has no attribute 'intercept'"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "clf=MLPClassifier()\n",
    "clf.fit(x_train,y_train)\n",
    "print(clf.score(x_test,y_test))\n",
    "print(clf.coefs_[0].shape)\n",
    "#print(clf.intercept_[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4, 2), (4, 1))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## forward propogation \n",
    "## without hidden layer\n",
    "\n",
    "import  numpy as np\n",
    "\n",
    "x=np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "y=np.array([[0,0,0,1]]).T\n",
    "x.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sig(z):\n",
    "    return 1/(1+ np.exp(-z))\n",
    "# till here same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights=2*np.random.random((2,1))-1  #range b/w -1 to 1\n",
    "bias=2*np.random.random(1)-1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.27055518],\n",
       "       [0.36223428],\n",
       "       [0.39979672],\n",
       "       [0.50495375]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output0 = x\n",
    "output = Sig(np.dot(output0,weights)+bias)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## With hidden layer\n",
    "\n",
    "wh=2*np.random.random((2,2))-1  #range b/w -1 to 1\n",
    "bh=2*np.random.random((1,2))-1\n",
    "\n",
    "wo=2*np.random.random((2,1))-1  #range b/w -1 to 1\n",
    "bo=2*np.random.random((1,1))-1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.15700185],\n",
       "       [0.15983646],\n",
       "       [0.17125251],\n",
       "       [0.17544858]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output0=x\n",
    "outputhidden= Sig(np.dot(output0,wh)+bh)\n",
    "\n",
    "output= Sig(np.dot(outputhidden,wo)+bo)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  including Backward propogation\n",
    "## updating weight to minimize errors\n",
    "\n",
    "def derivativeSig(z):\n",
    "    return Sig(z)*(1-Sig(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.24879532],\n",
       "        [-0.34661969]]), array([-0.38158945]))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## for no hidden layer\n",
    "\n",
    "weights=2*np.random.random((2,1))-1  #range b/w -1 to 1\n",
    "bias=2*np.random.random(1)-1\n",
    "lr=0.1\n",
    "weights,bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[5.46701272],\n",
       "        [5.46701272]]), array([-8.29326653]), array([[2.50133272e-04],\n",
       "        [5.59218479e-02],\n",
       "        [5.59218478e-02],\n",
       "        [9.33439132e-01]]))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for iter in range(10000):\n",
    "    output0=x\n",
    "    output = Sig(np.dot(output0,weights)+bias)\n",
    "    \n",
    "    first_term=output-y\n",
    "    input_for_last_layer=np.dot(output0,weights)+bias\n",
    "    second_term= derivativeSig(input_for_last_layer)\n",
    "    first_two=first_term*second_term\n",
    "    \n",
    "    changes=np.array([[0.0],[0.0]])\n",
    "    \n",
    "    for i in range(2):\n",
    "        for j in range(4):\n",
    "            changes[i][0]+= first_two[j][0]*output0[j][i]\n",
    "    weights=weights-lr*changes\n",
    "    bias_change=0.0\n",
    "    for j in range(4):\n",
    "        bias_change+=first_two[j][0]*1\n",
    "    bias=bias-lr*bias_change\n",
    "\n",
    "output = Sig(np.dot(x,weights)+bias)\n",
    "weights,bias,output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[5.47480039],\n",
       "        [5.47480039]]), array([-8.30491328]), array([[2.47237648e-04],\n",
       "        [5.57184582e-02],\n",
       "        [5.57184583e-02],\n",
       "        [9.33682802e-01]]))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## optimized using vector multiplication\n",
    "\n",
    "for iter in range(10000):\n",
    "    output0=x\n",
    "    output = Sig(np.dot(output0,weights)+bias)\n",
    "    \n",
    "    first_term=output-y\n",
    "    input_for_last_layer=np.dot(output0,weights)+bias\n",
    "    second_term= derivativeSig(input_for_last_layer)\n",
    "    first_two=first_term*second_term\n",
    "    \n",
    "    changes=np.dot(output0.T,first_two)\n",
    "    weights=weights-lr*changes\n",
    "    bias_change=np.sum(first_two)\n",
    "    bias=bias-lr*bias_change\n",
    "\n",
    "output = Sig(np.dot(x,weights)+bias)\n",
    "weights,bias,output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[5.47480039],\n",
       "        [5.47480039]]), array([-8.30491328]))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## for 1 hidden layer\n",
    "\n",
    "wh=2*np.random.random((2,2))-1  #range b/w -1 to 1\n",
    "bh=2*np.random.random((1,2))-1\n",
    "wo=2*np.random.random((2,1))-1\n",
    "bo=2*np.random.random((1,1))-1\n",
    "lr=0.1\n",
    "weights,bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.37018268, 0.37018266],\n",
       "        [0.37001117, 0.37001117],\n",
       "        [0.36998453, 0.36998453],\n",
       "        [0.36990813, 0.36990812]]), array([[1.07653871, 0.36928447],\n",
       "        [0.87962644, 0.29111287]]), array([[6.88622481, 6.44672088]]), array([[-0.86561118, -0.86494211],\n",
       "        [-0.54834706, -0.54901662]]), array([[0.88077337]]))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "for iter in range(10000):\n",
    "    output0=x\n",
    "    input_hidden=np.dot(output0,wh)+bh\n",
    "    output_hidden=Sig(input_hidden)\n",
    "    input_for_output_layer=np.dot(output_hidden,wo)+bo\n",
    "    output=Sig(input_for_output_layer)\n",
    "    \n",
    "    first_term_output_layer=output-y\n",
    "    second_term_output_layer= derivativeSig(input_for_last_layer)\n",
    "    first_two_output_layer=first_term_output_layer*second_term_output_layer\n",
    "    first_term_hidden_layer=first_term_output_layer*second_term_output_layer\n",
    "    \n",
    "    first_term_hidden_layer=np.dot(first_term_output_layer,wo.T)\n",
    "    second_term_hidden_layer=derivativeSig(input_hidden)\n",
    "    first_two_hidden_layer=first_term_hidden_layer*second_term_hidden_layer\n",
    "    \n",
    "    changes_output=np.dot(output_hidden.T,first_two_output_layer)\n",
    "    changes_output_bias=np.sum(first_two_output_layer, axis=0, keepdims=True)\n",
    "    \n",
    "    changes_hidden=np.dot(output0.T,first_two_hidden_layer)\n",
    "    changes_hidden_bias= np.sum(first_two_hidden_layer,axis=0,keepdims=True)\n",
    "    \n",
    "    \n",
    "    wo=wo-lr*changes_output\n",
    "    b0=bo-lr*changes_output_bias\n",
    "    wh=wh-lr*changes_hidden\n",
    "    bh=bh-lr*changes_hidden_bias\n",
    "\n",
    "output0=x\n",
    "input_hidden=np.dot(output0,wh)+bh\n",
    "output_hidden=Sig(input_hidden)\n",
    "input_for_output_layer=np.dot(output_hidden,wo)+bo\n",
    "output=Sig(input_for_output_layer)\n",
    "output,wh,bh,wo,bo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
